{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "인공신경망개론 최종과제.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM5kJ1N6ZrTKurwObC8F6gm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnjaejunlee/John-Lee/blob/master/Practice%20of%20Classifcation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mGwypF9qi-4"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.linear_model as lm\n",
        "import sklearn.svm as svm\n",
        "import sklearn.model_selection as mod_sel\n",
        "import sklearn.metrics as met\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.datasets import load_digits\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "from matplotlib.pyplot import colormaps as cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F71mqWgGqtSZ"
      },
      "source": [
        "## digit 일부 발췌 & 확인\n",
        "digits = load_digits()\n",
        "fig, ax_array = plt.subplots(7, 7)\n",
        "axes = ax_array.flatten()\n",
        "for i, ax in enumerate(axes):\n",
        "    ax.imshow(digits.images[i], cmap='gray_r')\n",
        "plt.setp(axes, xticks=[], yticks=[], frame_on=False)\n",
        "plt.tight_layout(h_pad=1, w_pad=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c_A2O_NqxuW"
      },
      "source": [
        "## X, y 설정 \n",
        "digits = load_digits()\n",
        "X = digits.data\n",
        "y = digits.target\n",
        "label = list(set(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF6GkCjx5Fr-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "images = digits.images\n",
        "images\n",
        "## Divide data for traning (70%) and test (30%)\n",
        "X_train, X_test, y_train, y_test = mod_sel.train_test_split(X, y, test_size=0.3, random_state=5)\n",
        "\n",
        "## Fit SVM to the data, X_train and y_train\n",
        "classifier = LogisticRegression(penalty= 'l2', C= 100, multi_class= 'multinomial', solver= 'lbfgs', max_iter= 10000, fit_intercept= True)\n",
        "classifier.fit(X_train,y_train)\n",
        "\n",
        "## Performance test\n",
        "y_pred_test = classifier.predict(X_test)\n",
        "accuracy_test = met.accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "y_pred_train = classifier.predict(X_train)\n",
        "accuracy_train = met.accuracy_score(y_train, y_pred_train)\n",
        "\n",
        "print(\"Accuracy(Naive):tested=\", accuracy_test, \"trained=\", accuracy_train )\n",
        "\n",
        "## Cross Entropy (Loss Function)\n",
        "y_prob = classifier.predict_proba(X_test) \n",
        "y_prob_train = classifier.predict_proba(X_train)\n",
        "print(\"Cross Entropy: tested=\", log_loss(y_test, y_prob), \"trained=\", log_loss(y_train, y_prob_train))\n",
        "\n",
        "## Evaluation: L-Fold Cross Validation\n",
        "y_pred = mod_sel.cross_val_predict(classifier, X, y, cv=5, n_jobs=4)\n",
        "c_mat = met.confusion_matrix(y, y_pred)\n",
        "###############################################################################\n",
        "import seaborn as sns\n",
        "print(\"\\n 교차검증 후 실제 final_accuracy (반올림 x):\", 100*met.accuracy_score(y,y_pred), \"%\\n\")\n",
        "print(classification_report(y, y_pred))\n",
        "print(\"\\nConfusion matrix\")\n",
        "print(c_mat)\n",
        "print(\"\\n\\n\")\n",
        "plt.figure(figsize=(15,15), frameon=True, facecolor='white', dpi=225)\n",
        "sns.heatmap(c_mat, fmt=\"d\", annot=True, linecolor='white', linewidths=3)\n",
        "plt.title(\"Confusion Matrix\", fontsize = 30)\n",
        "plt.rcParams.update({'font.size': 15})\n",
        "plt.ylabel('Actual Value',fontsize = 20)\n",
        "plt.xlabel('Prediction Value', fontsize=20)\n",
        "plt.savefig('confusionmatrix.png')\n",
        "plt.show()\n",
        "###############################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1qjaAYLwLWL"
      },
      "source": [
        "## Checking Estimated Probability of Dataset (Partial Check)\n",
        "y_prob = classifier.predict_proba(X)\n",
        "print('Classes: ', classifier.classes_)\n",
        "print( 'Original/Predicted label: ', y[1], y_pred[1] )\n",
        "print( 'Estimated probabilities: ', y_prob[1,:]) ## sigmoid function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_VMa7ZXD1n-"
      },
      "source": [
        "## 결과 확인\n",
        "f=plt.figure(figsize=(16,12), facecolor='lightgreen', dpi=None)\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "    image = images[i]\n",
        "    sub =f.add_subplot(7, 7, i+1)\n",
        "    sub.imshow(image, cmap='GnBu_r')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.rcParams.update({'font.size': 15})\n",
        "    sub.set_title('predict: %i\\n actual: %i' % (y_pred[i], y[i]))\n",
        "    plt.subplots_adjust(hspace =1.2,)\n",
        "\n",
        "f.suptitle('Compare Prediction and Targets Value', fontsize = 30)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ9-uJ4LQKPT"
      },
      "source": [
        "###### 학습된 prediction과 실제 y test값 비교\n",
        "up_count = 0\n",
        "down_count = 0\n",
        "for i in range(axes.size):\n",
        "    if y_pred[i]==y[i]: \n",
        "        up_count = up_count+1\n",
        "    else: down_count = down_count +1  ##y_pred 값과 y_test 값을 비교해서 같으면 up, 다르면 down\n",
        "print (up_count, down_count, up_count + down_count, up_count/(up_count + down_count)) ##Data가 적기 때문에 accuracy 조금 낮음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T_4uAtRGpEI"
      },
      "source": [
        "## 최종 각 class 별 intercept & theta 값 확인 \n",
        "print( \"theta_0 (intercept) = \") \n",
        "print(classifier.intercept_) ## class 별 intercept 값\n",
        "print( \"theta[1:M] = \" )\n",
        "print(classifier.coef_) ## class별 theta 값"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92XgUXlvIrYK"
      },
      "source": [
        "## ROC_AUC (open source 활용)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import cycle\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "\n",
        "# Binarize the output\n",
        "y_bin = label_binarize(y, classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "n_classes = 10\n",
        "\n",
        "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_bin, test_size=.3)\n",
        "# Learn to predict each class against the other\n",
        "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', C=0.01, probability=True, gamma='auto'))\n",
        "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"macro\"], tpr[\"macro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr[2], tpr[2], color='blue', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}